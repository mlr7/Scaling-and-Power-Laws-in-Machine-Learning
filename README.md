# Scaling-and-Power-Laws-in-Machine-Learning
A collection of papers, datasets, code, and links tracking scaling studies and power law behavior in machine learning

(this page is a work in progress)

## Scaling in Transformer-based Neural Language Models

#### Kaplan 2020: Scaling Laws for Neural Language Models

Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. "Scaling laws for neural language models." arXiv preprint arXiv:2001.08361 (2020).

https://arxiv.org/abs/2001.08361
 

Summary: 

* Performance depends strongly on scale, weakly on model shape

* Smooth power laws

* Universality of overfitting

* Universality of training

* Transfer improves with test performance

* Sample efficiency

* Convergence is ineffecient

* Optimal batch size

#### Scaling Laws of Deep Neural Networks: Explaining Neural Scaling Law, Jaehoon Lee, June 4, 2021

https://www.youtube.com/watch?v=A8F4Qga3NaM

![](img/Lee2021_ExplainingNeuralScaling2.png.png)

#### The World that Bert Built: Huge "Foundation Models" are Turbocharging AI Progress, Economist, June 11, 2022

https://www.economist.com/interactive/briefing/2022/06/11/huge-foundation-models-are-turbo-charging-ai-progress

![](img/blessings1.png)

## Scaling of Traditional (Shallow) Machine Learning Algos (non-deep learning models)

#### The smallest sample size for the desired diagnosis accuracy, Floares 2017

Floares, A., Marius Ferisgan, Daniela Onita, Andrei Ciuparu, G. Calin, and F. Manolache. "The smallest sample size for the desired diagnosis accuracy." Int J Oncol Cancer Ther 2 (2017): 13-19.

https://iaras.org/iaras/filedownloads/ijoct/2017/028-0004(2017).pdf

#### Overview of Machine Learning Process Modelling, Brumen 2021

Brumen, Boštjan, Aleš Černezel, and Leon Bošnjak. "Overview of Machine Learning Process Modelling." Entropy 23, no. 9 (2021): 1123.

https://www.mdpi.com/1099-4300/23/9/1123

#### Learning Curve Theory, Hutter (Deep Mind) 2021

Hutter, Marcus. "Learning curve theory." arXiv preprint arXiv:2102.04074 (2021).

https://arxiv.org/abs/2102.04074

## Phase Transitions

#### Compute Trends Across Three Eras of Machine Learning, Jaime Sevilla, Feb 11, 2022

https://arxiv.org/abs/2202.05924

Sevilla, Jaime, Lennart Heim, Anson Ho, Tamay Besiroglu, Marius Hobbhahn, and Pablo Villalobos. "Compute trends across three eras of machine learning." arXiv preprint arXiv:2202.05924 (2022).

![](img/flops0.png)

![](img/flops1.png)


#### Phase Transitions and AGI, Ege Erdil, Metaculus, March 17, 2022

https://www.lesswrong.com/posts/ftdCgGmkQ3bPyDadA/phase-transitions-and-agi

## The Bitter Lesson, Richard Sutton

* http://www.incompleteideas.net/IncIdeas/BitterLesson.html

* https://www.kdnuggets.com/2020/11/revisiting-sutton-bitter-lesson-ai.html

## General

#### DEEP LEARNING SCALING IS PREDICTABLE, EMPIRICALLY, Hestness 2017

Hestness, Joel, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md Patwary, Mostofa Ali, Yang Yang, and Yanqi Zhou. "Deep learning scaling is predictable, empirically." arXiv preprint arXiv:1712.00409 (2017).

https://arxiv.org/abs/1712.00409

#### Power-law scaling to assist with key challenges in artificial intelligence, Meir 2020

Meir, Yuval, Shira Sardi, Shiri Hodassman, Karin Kisos, Itamar Ben-Noam, Amir Goldental, and Ido Kanter. "Power-law scaling to assist with key challenges in artificial intelligence." Scientific reports 10, no. 1 (2020): 1-7.

https://www.nature.com/articles/s41598-020-76764-1
