# Scaling-and-Power-Laws-in-Machine-Learning
A collection of papers, datasets, code, and links tracking scaling studies and power law behavior in machine learning

(this page is a work in progress)

## Scaling in Transformer-based Neural Language Models

#### X. Kaplan 2020: Scaling Laws for Neural Language Models

Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. "Scaling laws for neural language models." arXiv preprint arXiv:2001.08361 (2020).

https://arxiv.org/abs/2001.08361
 

Summary: 

* Performance depends strongly on scale, weakly on model shape

* Smooth power laws

* Universality of overfitting

* Universality of training

* Transfer improves with test performance

* Sample efficiency

* Convergence is ineffecient

* Optimal batch size

#### X. A Neural Scaling Law from the Dimension of the Data Manifold, Sharma, Kaplan 2020

Sharma, Utkarsh, and Jared Kaplan. "A neural scaling law from the dimension of the data manifold." arXiv preprint arXiv:2004.10802 (2020).

https://arxiv.org/abs/2004.10802

#### X. Scaling Laws of Deep Neural Networks: Explaining Neural Scaling Law, Jaehoon Lee, June 4, 2021

https://www.youtube.com/watch?v=A8F4Qga3NaM

![](img/Lee2021_ExplainingNeuralScaling2.png.png)

#### X. The World that Bert Built: Huge "Foundation Models" are Turbocharging AI Progress, Economist, June 11, 2022

https://www.economist.com/interactive/briefing/2022/06/11/huge-foundation-models-are-turbo-charging-ai-progress

![](img/blessings1.png)

#### X. Training Compute-Optimal Large Language Models, Hoffmann, March 29, 2022

Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas et al. "Training Compute-Optimal Large Language Models." arXiv preprint arXiv:2203.15556 (2022).

https://arxiv.org/abs/2203.15556

#### X. New Scaling Laws for Large Language Models, April 1, 2022

https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models

## Scaling in Computer Vision Models

#### X. On Power Laws in Deep Ensembles, Lobacheva 2021

Lobacheva, Ekaterina, et al. "On power laws in deep ensembles." Advances In Neural Information Processing Systems 33 (2020): 2375-2385.

https://arxiv.org/abs/2007.08483#:~:text=Ensembles%20of%20deep%20neural%20networks,and%20lead%20to%20accuracy%20improvement


#### X. A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your Pre-training Effective?. Mikami 2021

Mikami, Hiroaki, Kenji Fukumizu, Shogo Murai, Shuji Suzuki, Yuta Kikuchi, Taiji Suzuki, Shin-ichi Maeda, and Kohei Hayashi. "A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your Pre-training Effective?." arXiv preprint arXiv:2108.11018 (2021).

https://arxiv.org/abs/2108.11018

#### X. Task2Sim: Towards Effective Pre-Training and Transfer From Synthetic Data, Mishra 2022 (CVPR)

Mishra, Samarth, Rameswar Panda, Cheng Perng Phoo, Chun-Fu Richard Chen, Leonid Karlinsky, Kate Saenko, Venkatesh Saligrama, and Rogerio S. Feris. "Task2Sim: Towards Effective Pre-training and Transfer from Synthetic Data." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9194-9204. 2022.

https://openaccess.thecvf.com/content/CVPR2022/html/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.html

#### X. Beyond neural scaling laws: beating power law scaling via data pruning, Sorscher 2022

https://arxiv.org/abs/2206.14486

Sorscher, Ben, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari S. Morcos. "Beyond neural scaling laws: beating power law scaling via data pruning." arXiv preprint arXiv:2206.14486 (2022).
## Scaling of Traditional (Shallow) Machine Learning Algos (non-deep learning models)

#### X. The smallest sample size for the desired diagnosis accuracy, Floares 2017

Floares, A., Marius Ferisgan, Daniela Onita, Andrei Ciuparu, G. Calin, and F. Manolache. "The smallest sample size for the desired diagnosis accuracy." Int J Oncol Cancer Ther 2 (2017): 13-19.

https://iaras.org/iaras/filedownloads/ijoct/2017/028-0004(2017).pdf

#### X. Overview of Machine Learning Process Modelling, Brumen 2021

Brumen, Boštjan, Aleš Černezel, and Leon Bošnjak. "Overview of Machine Learning Process Modelling." Entropy 23, no. 9 (2021): 1123.

https://www.mdpi.com/1099-4300/23/9/1123

#### X. Learning Curve Theory, Hutter (Deep Mind) 2021

Hutter, Marcus. "Learning curve theory." arXiv preprint arXiv:2102.04074 (2021).

https://arxiv.org/abs/2102.04074

## Phase Transitions

#### X. Compute Trends Across Three Eras of Machine Learning, Jaime Sevilla, Feb 11, 2022

https://arxiv.org/abs/2202.05924

Sevilla, Jaime, Lennart Heim, Anson Ho, Tamay Besiroglu, Marius Hobbhahn, and Pablo Villalobos. "Compute trends across three eras of machine learning." arXiv preprint arXiv:2202.05924 (2022).

![](img/flops0.png)

![](img/flops1.png)


#### X. Phase Transitions and AGI, Ege Erdil, Metaculus, March 17, 2022

https://www.lesswrong.com/posts/ftdCgGmkQ3bPyDadA/phase-transitions-and-agi

## The Bitter Lesson, Richard Sutton

* http://www.incompleteideas.net/IncIdeas/BitterLesson.html

* https://www.kdnuggets.com/2020/11/revisiting-sutton-bitter-lesson-ai.html

## General

#### X. DEEP LEARNING SCALING IS PREDICTABLE, EMPIRICALLY, Hestness 2017

Hestness, Joel, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md Patwary, Mostofa Ali, Yang Yang, and Yanqi Zhou. "Deep learning scaling is predictable, empirically." arXiv preprint arXiv:1712.00409 (2017).

https://arxiv.org/abs/1712.00409

#### X. Power-law scaling to assist with key challenges in artificial intelligence, Meir 2020

Meir, Yuval, Shira Sardi, Shiri Hodassman, Karin Kisos, Itamar Ben-Noam, Amir Goldental, and Ido Kanter. "Power-law scaling to assist with key challenges in artificial intelligence." Scientific reports 10, no. 1 (2020): 1-7.

https://www.nature.com/articles/s41598-020-76764-1

## Notes

* (add computer vision "double power law" scaling paper)

* (add other cvpr2022 scaling paper) (vision transformer? or synthetic-to-real something . . . find)
